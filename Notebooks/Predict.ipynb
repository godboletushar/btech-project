{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install ampligraph==2.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHHvpW749n2q",
        "outputId": "dc090e9c-9fb7-4dc5-f37b-d39e4fd41589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ampligraph==2.0.0 in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (1.22.4)\n",
            "Requirement already satisfied: pytest>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (7.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (1.2.2)\n",
            "Requirement already satisfied: deap>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (1.3.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: tqdm>=4.23.4 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (1.5.3)\n",
            "Requirement already satisfied: sphinx==5.0.2 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (5.0.2)\n",
            "Requirement already satisfied: myst-parser==0.18.0 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (0.18.0)\n",
            "Requirement already satisfied: docutils<0.18 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (0.16)\n",
            "Requirement already satisfied: sphinx-rtd-theme==1.0.0 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-bibtex==2.4.2 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (2.4.2)\n",
            "Requirement already satisfied: beautifultable>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: pyyaml>=3.13 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (6.0)\n",
            "Requirement already satisfied: rdflib>=4.2.2 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (6.3.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (3.1)\n",
            "Requirement already satisfied: flake8>=3.7.7 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (6.0.0)\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (3.7.1)\n",
            "Requirement already satisfied: docopt==0.6.2 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (0.6.2)\n",
            "Requirement already satisfied: schema==0.7.5 in /usr/local/lib/python3.10/dist-packages (from ampligraph==2.0.0) (0.7.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph==2.0.0) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph==2.0.0) (2.2.0)\n",
            "Requirement already satisfied: mdit-py-plugins~=0.3.0 in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph==2.0.0) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph==2.0.0) (4.5.0)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema==0.7.5->ampligraph==2.0.0) (0.6.0.post1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (2.14.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (2.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph==2.0.0) (23.1)\n",
            "Requirement already satisfied: pybtex>=0.24 in /usr/local/lib/python3.10/dist-packages (from sphinxcontrib-bibtex==2.4.2->ampligraph==2.0.0) (0.24.0)\n",
            "Requirement already satisfied: pybtex-docutils>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinxcontrib-bibtex==2.4.2->ampligraph==2.0.0) (1.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from beautifultable>=0.7.0->ampligraph==2.0.0) (0.2.6)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from flake8>=3.7.7->ampligraph==2.0.0) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.11.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from flake8>=3.7.7->ampligraph==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: pyflakes<3.1.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flake8>=3.7.7->ampligraph==2.0.0) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph==2.0.0) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph==2.0.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph==2.0.0) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph==2.0.0) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph==2.0.0) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph==2.0.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph==2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.1->ampligraph==2.0.0) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph==2.0.0) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph==2.0.0) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=4.2.2->ampligraph==2.0.0) (0.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->ampligraph==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=4.2.2->ampligraph==2.0.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->myst-parser==0.18.0->ampligraph==2.0.0) (2.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=1.0.0->myst-parser==0.18.0->ampligraph==2.0.0) (0.1.2)\n",
            "Requirement already satisfied: latexcodec>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from pybtex>=0.24->sphinxcontrib-bibtex==2.4.2->ampligraph==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph==2.0.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph==2.0.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph==2.0.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph==2.0.0) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-UYNKEH61OB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../..')\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ampligraph.datasets import load_from_csv\n",
        "# Uncomment the below block if the files 'triples_train.csv' and 'triples_test.csv' do not exist\n",
        "'''\n",
        "from ampligraph.evaluation import train_test_split_no_unseen\n",
        "dataset = load_from_csv('/content/', 'triples.txt')\n",
        "dataset_train, dataset_test = train_test_split_no_unseen(dataset, test_size = 0.3)\n",
        "with open('triples_train.txt', mode = 'w') as train_file:\n",
        "  for entry in dataset_train:\n",
        "    train_file.write(entry[0] + \"\\t\" + entry[1] + \"\\t\" + entry[2] + \"\\n\")\n",
        "\n",
        "with open('triples_test.txt', mode = 'w') as test_file:\n",
        "  for entry in dataset_test:\n",
        "    test_file.write(entry[0] + \"\\t\" + entry[1] + \"\\t\" + entry[2] + \"\\n\")\n",
        "'''\n",
        "# Comment the below two lines if the files 'triples_train.csv' and 'triples_test.csv' do not exist\n",
        "dataset_train = load_from_csv('/content/', 'triples_train.txt')\n",
        "dataset_test = load_from_csv('/content/', 'triples_test.txt')"
      ],
      "metadata": {
        "id": "FKY6oi-95Hup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Import the KGE model\n",
        "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
        "\n",
        "# # you can continue training from where you left after restoring the model\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./transe_train_logs')\n",
        "\n",
        "# # create the model with transe scoring function\n",
        "model = ScoringBasedEmbeddingModel(eta=5,\n",
        "                                   k=300,\n",
        "                                   scoring_type='TransE')\n",
        "\n",
        "# # you can either use optimizers/regularizers/loss/initializers with default values or you can \n",
        "# # import it and customize the hyperparameters and pass it to compile\n",
        "\n",
        "# # Let's create an adam optimizer with customized learning rate =0.005\n",
        "# # adam = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "# # Let's compile the model with self_advarsarial loss of default parameters\n",
        "model.compile(optimizer='adam', loss='self_adversarial')\n",
        "\n",
        "# # fit the model to data.\n",
        "# model.fit(dataset['train'],\n",
        "#              batch_size=10000,\n",
        "#              epochs=10,\n",
        "#              callbacks=[tensorboard_callback])\n",
        "\n",
        "model.fit(dataset_train, batch_size = 16, epochs = 10)\n",
        "\n",
        "# # the training can be visualised using the following command:\n",
        "# # tensorboard --logdir='./transe_train_logs' --port=8891 \n",
        "# # open the browser and go to the following URL: http://127.0.0.1:8891/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPVcG6ogBYzH",
        "outputId": "73f2abf2-33f0-4b62-d990-92aa33ff1fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 4s 52ms/step - loss: 259.8446\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 203.3035\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 163.0937\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 134.1717\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 113.1062\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 97.4750\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 85.5642\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 76.2966\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 68.9118\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 62.9029\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcb1884bb80>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = model.predict(dataset_test, \n",
        "#                        batch_size=100)"
      ],
      "metadata": {
        "id": "PcFZeSpNFqMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred"
      ],
      "metadata": {
        "id": "Bf2AOJlcGD58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # evaluate on the test set\n",
        "# ranks = model.evaluate(dataset_test,     # test set\n",
        "#                        batch_size=100,      # evaluation batch size\n",
        "#                        corrupt_side='s,o',   # sides to corrupt for scoring and ranking\n",
        "#                        use_filter = {'train': dataset_train,\n",
        "#                                       'test': dataset_test}\n",
        "#                        )\n",
        "\n",
        "# # import the evaluation metrics\n",
        "# from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
        "\n",
        "# print('MR:', mr_score(ranks))\n",
        "# print('MRR:', mrr_score(ranks))\n",
        "# print('hits@1:', hits_at_n_score(ranks, 1))\n",
        "# print('hits@10:', hits_at_n_score(ranks, 10))"
      ],
      "metadata": {
        "id": "-e9dhB8fGgys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ampligraph.evaluation.metrics import mr_score, mrr_score, hits_at_n_score\n",
        "rank_head = model.evaluate(dataset_test, \n",
        "                           batch_size = 100,\n",
        "                           corrupt_side = 's',\n",
        "                           use_filter = {'train' : dataset_train,\n",
        "                                         'test' :  dataset_test}\n",
        "                           )\n",
        "print(\"MR:\", mr_score(rank_head))\n",
        "print(\"MRR:\", mrr_score(rank_head))\n",
        "print(\"Hits@1:\", hits_at_n_score(rank_head, 1))\n",
        "print(\"Hits@3:\", hits_at_n_score(rank_head, 3))\n",
        "print(\"Hits@5:\", hits_at_n_score(rank_head, 5))\n",
        "print(\"Hits@10:\", hits_at_n_score(rank_head, 10))\n",
        "print(rank_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJFzatVTvESV",
        "outputId": "def2578a-c297-43ac-c214-6140fa18fddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 9s 1s/step\n",
            "MR: 108.60984848484848\n",
            "MRR: 0.21344923607321992\n",
            "Hits@1: 0.003787878787878788\n",
            "Hits@3: 0.38446969696969696\n",
            "Hits@5: 0.4772727272727273\n",
            "Hits@10: 0.5454545454545454\n",
            "[[307]\n",
            " [ 25]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [327]\n",
            " [  4]\n",
            " [309]\n",
            " [ 56]\n",
            " [  2]\n",
            " [ 56]\n",
            " [  7]\n",
            " [146]\n",
            " [  2]\n",
            " [136]\n",
            " [132]\n",
            " [ 99]\n",
            " [114]\n",
            " [ 84]\n",
            " [325]\n",
            " [  3]\n",
            " [  2]\n",
            " [294]\n",
            " [ 69]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 48]\n",
            " [  2]\n",
            " [ 16]\n",
            " [ 72]\n",
            " [179]\n",
            " [ 11]\n",
            " [  2]\n",
            " [  6]\n",
            " [  9]\n",
            " [302]\n",
            " [  5]\n",
            " [ 64]\n",
            " [  9]\n",
            " [  2]\n",
            " [353]\n",
            " [  2]\n",
            " [111]\n",
            " [162]\n",
            " [  1]\n",
            " [  5]\n",
            " [  2]\n",
            " [ 11]\n",
            " [  3]\n",
            " [  3]\n",
            " [  2]\n",
            " [608]\n",
            " [  2]\n",
            " [  5]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [  4]\n",
            " [  5]\n",
            " [120]\n",
            " [  4]\n",
            " [  2]\n",
            " [338]\n",
            " [154]\n",
            " [219]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 31]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 25]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  4]\n",
            " [  1]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [  3]\n",
            " [  3]\n",
            " [ 73]\n",
            " [  3]\n",
            " [241]\n",
            " [  3]\n",
            " [  2]\n",
            " [787]\n",
            " [  2]\n",
            " [723]\n",
            " [  6]\n",
            " [  2]\n",
            " [234]\n",
            " [181]\n",
            " [407]\n",
            " [ 42]\n",
            " [603]\n",
            " [332]\n",
            " [  3]\n",
            " [  4]\n",
            " [  2]\n",
            " [787]\n",
            " [147]\n",
            " [  6]\n",
            " [  2]\n",
            " [  5]\n",
            " [292]\n",
            " [  3]\n",
            " [313]\n",
            " [244]\n",
            " [640]\n",
            " [501]\n",
            " [ 46]\n",
            " [  2]\n",
            " [291]\n",
            " [ 31]\n",
            " [ 56]\n",
            " [  4]\n",
            " [ 71]\n",
            " [  2]\n",
            " [  3]\n",
            " [  3]\n",
            " [247]\n",
            " [  7]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 26]\n",
            " [  3]\n",
            " [ 32]\n",
            " [411]\n",
            " [220]\n",
            " [  4]\n",
            " [ 72]\n",
            " [  2]\n",
            " [355]\n",
            " [  5]\n",
            " [533]\n",
            " [764]\n",
            " [ 41]\n",
            " [  2]\n",
            " [  7]\n",
            " [299]\n",
            " [ 12]\n",
            " [640]\n",
            " [166]\n",
            " [  2]\n",
            " [  6]\n",
            " [  2]\n",
            " [  4]\n",
            " [  2]\n",
            " [ 34]\n",
            " [  6]\n",
            " [367]\n",
            " [  2]\n",
            " [  3]\n",
            " [211]\n",
            " [ 77]\n",
            " [ 10]\n",
            " [ 40]\n",
            " [211]\n",
            " [ 12]\n",
            " [661]\n",
            " [  9]\n",
            " [252]\n",
            " [429]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 37]\n",
            " [  6]\n",
            " [  2]\n",
            " [134]\n",
            " [165]\n",
            " [241]\n",
            " [168]\n",
            " [ 22]\n",
            " [159]\n",
            " [  2]\n",
            " [  2]\n",
            " [  4]\n",
            " [607]\n",
            " [ 34]\n",
            " [  4]\n",
            " [ 51]\n",
            " [  2]\n",
            " [  6]\n",
            " [454]\n",
            " [122]\n",
            " [355]\n",
            " [  2]\n",
            " [  4]\n",
            " [ 24]\n",
            " [574]\n",
            " [  2]\n",
            " [  4]\n",
            " [  3]\n",
            " [ 18]\n",
            " [  4]\n",
            " [ 27]\n",
            " [240]\n",
            " [  2]\n",
            " [233]\n",
            " [  2]\n",
            " [  4]\n",
            " [  3]\n",
            " [235]\n",
            " [  3]\n",
            " [442]\n",
            " [  5]\n",
            " [  5]\n",
            " [ 16]\n",
            " [  3]\n",
            " [505]\n",
            " [  3]\n",
            " [ 48]\n",
            " [  2]\n",
            " [ 79]\n",
            " [ 14]\n",
            " [ 12]\n",
            " [ 46]\n",
            " [  8]\n",
            " [ 81]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 41]\n",
            " [ 90]\n",
            " [  3]\n",
            " [415]\n",
            " [625]\n",
            " [  3]\n",
            " [  6]\n",
            " [764]\n",
            " [  7]\n",
            " [  2]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [  4]\n",
            " [ 33]\n",
            " [ 11]\n",
            " [  4]\n",
            " [  2]\n",
            " [  4]\n",
            " [770]\n",
            " [  7]\n",
            " [688]\n",
            " [ 15]\n",
            " [  2]\n",
            " [478]\n",
            " [  3]\n",
            " [  4]\n",
            " [458]\n",
            " [449]\n",
            " [  2]\n",
            " [320]\n",
            " [193]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  9]\n",
            " [  2]\n",
            " [  4]\n",
            " [  4]\n",
            " [  2]\n",
            " [184]\n",
            " [  2]\n",
            " [  2]\n",
            " [184]\n",
            " [  2]\n",
            " [448]\n",
            " [ 73]\n",
            " [  2]\n",
            " [ 16]\n",
            " [  2]\n",
            " [  3]\n",
            " [139]\n",
            " [  2]\n",
            " [  6]\n",
            " [  5]\n",
            " [ 73]\n",
            " [243]\n",
            " [  2]\n",
            " [ 85]\n",
            " [243]\n",
            " [ 76]\n",
            " [ 37]\n",
            " [  6]\n",
            " [  6]\n",
            " [417]\n",
            " [  2]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [  5]\n",
            " [ 60]\n",
            " [ 23]\n",
            " [ 84]\n",
            " [  2]\n",
            " [175]\n",
            " [  2]\n",
            " [529]\n",
            " [ 87]\n",
            " [  2]\n",
            " [428]\n",
            " [  2]\n",
            " [ 27]\n",
            " [  2]\n",
            " [  3]\n",
            " [698]\n",
            " [  2]\n",
            " [ 10]\n",
            " [ 20]\n",
            " [214]\n",
            " [ 35]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 30]\n",
            " [523]\n",
            " [  3]\n",
            " [ 11]\n",
            " [108]\n",
            " [250]\n",
            " [  2]\n",
            " [  4]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [595]\n",
            " [ 16]\n",
            " [ 80]\n",
            " [527]\n",
            " [469]\n",
            " [511]\n",
            " [178]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [  4]\n",
            " [  3]\n",
            " [  5]\n",
            " [570]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 29]\n",
            " [ 81]\n",
            " [  3]\n",
            " [350]\n",
            " [657]\n",
            " [  2]\n",
            " [  4]\n",
            " [166]\n",
            " [ 46]\n",
            " [  4]\n",
            " [133]\n",
            " [  2]\n",
            " [262]\n",
            " [ 90]\n",
            " [  2]\n",
            " [  5]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 39]\n",
            " [  3]\n",
            " [  7]\n",
            " [  3]\n",
            " [ 51]\n",
            " [  2]\n",
            " [  3]\n",
            " [  6]\n",
            " [  3]\n",
            " [555]\n",
            " [ 11]\n",
            " [199]\n",
            " [  2]\n",
            " [  3]\n",
            " [  4]\n",
            " [258]\n",
            " [  6]\n",
            " [  3]\n",
            " [  2]\n",
            " [ 85]\n",
            " [  2]\n",
            " [ 19]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 78]\n",
            " [  2]\n",
            " [  3]\n",
            " [  3]\n",
            " [ 34]\n",
            " [ 68]\n",
            " [  4]\n",
            " [ 32]\n",
            " [294]\n",
            " [  4]\n",
            " [613]\n",
            " [  2]\n",
            " [  3]\n",
            " [492]\n",
            " [194]\n",
            " [  6]\n",
            " [102]\n",
            " [  2]\n",
            " [ 18]\n",
            " [  3]\n",
            " [  2]\n",
            " [  8]\n",
            " [509]\n",
            " [  2]\n",
            " [ 63]\n",
            " [ 35]\n",
            " [  3]\n",
            " [  3]\n",
            " [385]\n",
            " [ 20]\n",
            " [  3]\n",
            " [760]\n",
            " [533]\n",
            " [265]\n",
            " [ 17]\n",
            " [  2]\n",
            " [  3]\n",
            " [258]\n",
            " [164]\n",
            " [768]\n",
            " [ 28]\n",
            " [646]\n",
            " [  2]\n",
            " [673]\n",
            " [ 13]\n",
            " [  2]\n",
            " [ 36]\n",
            " [  3]\n",
            " [208]\n",
            " [111]\n",
            " [  2]\n",
            " [  6]\n",
            " [  3]\n",
            " [  2]\n",
            " [  4]\n",
            " [341]\n",
            " [  4]\n",
            " [  3]\n",
            " [  6]\n",
            " [295]\n",
            " [  3]\n",
            " [784]\n",
            " [ 58]\n",
            " [  2]\n",
            " [  3]\n",
            " [  3]\n",
            " [677]\n",
            " [  5]\n",
            " [268]\n",
            " [ 89]\n",
            " [ 15]\n",
            " [634]\n",
            " [  6]\n",
            " [300]\n",
            " [ 84]\n",
            " [  2]\n",
            " [ 12]\n",
            " [633]\n",
            " [  6]\n",
            " [  3]\n",
            " [  3]\n",
            " [  3]\n",
            " [397]\n",
            " [  2]\n",
            " [  5]\n",
            " [  5]\n",
            " [ 75]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 11]\n",
            " [  9]\n",
            " [  2]\n",
            " [  9]\n",
            " [ 11]\n",
            " [  4]\n",
            " [  2]\n",
            " [  3]\n",
            " [139]\n",
            " [554]\n",
            " [  2]\n",
            " [  2]\n",
            " [212]\n",
            " [  2]\n",
            " [183]\n",
            " [140]\n",
            " [ 97]\n",
            " [  8]\n",
            " [  4]\n",
            " [  2]\n",
            " [  4]\n",
            " [ 17]\n",
            " [ 22]\n",
            " [  2]\n",
            " [  2]\n",
            " [216]\n",
            " [  7]\n",
            " [732]\n",
            " [326]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [218]\n",
            " [  2]\n",
            " [148]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 60]\n",
            " [  2]\n",
            " [  2]\n",
            " [  4]\n",
            " [435]\n",
            " [365]\n",
            " [  5]\n",
            " [  3]\n",
            " [  3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ampligraph.evaluation.metrics import mr_score, mrr_score, hits_at_n_score\n",
        "rank_tail = model.evaluate(dataset_test, \n",
        "                           batch_size = 100,\n",
        "                           corrupt_side = 'o',\n",
        "                           use_filter = {'train' : dataset_train,\n",
        "                                         'test' :  dataset_test}\n",
        "                           )\n",
        "print(\"MR:\", mr_score(rank_tail))\n",
        "print(\"MRR:\", mrr_score(rank_tail))\n",
        "print(\"Hits@1:\", hits_at_n_score(rank_tail, 1))\n",
        "print(\"Hits@3:\", hits_at_n_score(rank_head, 3))\n",
        "print(\"Hits@5:\", hits_at_n_score(rank_head, 5))\n",
        "print(\"Hits@10:\", hits_at_n_score(rank_tail, 10))\n",
        "print(rank_tail)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVwU596H0d3i",
        "outputId": "09c161fb-7774-4170-d7ef-4a265afee65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 442ms/step\n",
            "MR: 104.71780303030303\n",
            "MRR: 0.2202356299068447\n",
            "Hits@1: 0.003787878787878788\n",
            "Hits@3: 0.38446969696969696\n",
            "Hits@5: 0.4772727272727273\n",
            "Hits@10: 0.5852272727272727\n",
            "[[ 65]\n",
            " [ 37]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [  6]\n",
            " [ 10]\n",
            " [700]\n",
            " [617]\n",
            " [  2]\n",
            " [327]\n",
            " [  7]\n",
            " [452]\n",
            " [  2]\n",
            " [449]\n",
            " [169]\n",
            " [575]\n",
            " [ 27]\n",
            " [268]\n",
            " [243]\n",
            " [  2]\n",
            " [  4]\n",
            " [139]\n",
            " [114]\n",
            " [  6]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 10]\n",
            " [656]\n",
            " [  2]\n",
            " [  2]\n",
            " [362]\n",
            " [169]\n",
            " [  9]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 37]\n",
            " [303]\n",
            " [  3]\n",
            " [407]\n",
            " [  4]\n",
            " [  3]\n",
            " [ 51]\n",
            " [  2]\n",
            " [197]\n",
            " [457]\n",
            " [  1]\n",
            " [  2]\n",
            " [  6]\n",
            " [  7]\n",
            " [  2]\n",
            " [  4]\n",
            " [  3]\n",
            " [ 37]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 13]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [270]\n",
            " [  6]\n",
            " [  2]\n",
            " [340]\n",
            " [ 44]\n",
            " [116]\n",
            " [  3]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 60]\n",
            " [  2]\n",
            " [  2]\n",
            " [193]\n",
            " [  6]\n",
            " [  4]\n",
            " [  2]\n",
            " [  2]\n",
            " [  1]\n",
            " [  3]\n",
            " [  8]\n",
            " [  4]\n",
            " [  6]\n",
            " [  2]\n",
            " [ 86]\n",
            " [  2]\n",
            " [206]\n",
            " [  3]\n",
            " [  3]\n",
            " [760]\n",
            " [  2]\n",
            " [ 22]\n",
            " [  3]\n",
            " [  2]\n",
            " [ 15]\n",
            " [399]\n",
            " [665]\n",
            " [  7]\n",
            " [ 43]\n",
            " [323]\n",
            " [  2]\n",
            " [  2]\n",
            " [  4]\n",
            " [763]\n",
            " [135]\n",
            " [  5]\n",
            " [  3]\n",
            " [  3]\n",
            " [151]\n",
            " [  2]\n",
            " [308]\n",
            " [621]\n",
            " [ 15]\n",
            " [ 37]\n",
            " [ 81]\n",
            " [  5]\n",
            " [347]\n",
            " [  3]\n",
            " [ 53]\n",
            " [  6]\n",
            " [  3]\n",
            " [  3]\n",
            " [  5]\n",
            " [  3]\n",
            " [638]\n",
            " [  5]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 40]\n",
            " [  3]\n",
            " [ 56]\n",
            " [250]\n",
            " [ 11]\n",
            " [ 12]\n",
            " [118]\n",
            " [  2]\n",
            " [619]\n",
            " [  4]\n",
            " [485]\n",
            " [264]\n",
            " [662]\n",
            " [  2]\n",
            " [  4]\n",
            " [ 58]\n",
            " [  7]\n",
            " [631]\n",
            " [470]\n",
            " [  3]\n",
            " [  3]\n",
            " [  2]\n",
            " [  4]\n",
            " [  2]\n",
            " [102]\n",
            " [  4]\n",
            " [224]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 57]\n",
            " [475]\n",
            " [  4]\n",
            " [ 15]\n",
            " [215]\n",
            " [ 47]\n",
            " [362]\n",
            " [  6]\n",
            " [150]\n",
            " [291]\n",
            " [  3]\n",
            " [  2]\n",
            " [246]\n",
            " [  2]\n",
            " [  2]\n",
            " [698]\n",
            " [197]\n",
            " [ 46]\n",
            " [ 56]\n",
            " [143]\n",
            " [310]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [347]\n",
            " [ 92]\n",
            " [  3]\n",
            " [ 82]\n",
            " [  2]\n",
            " [  3]\n",
            " [771]\n",
            " [196]\n",
            " [368]\n",
            " [  2]\n",
            " [  4]\n",
            " [ 17]\n",
            " [771]\n",
            " [  2]\n",
            " [  7]\n",
            " [  6]\n",
            " [  7]\n",
            " [  9]\n",
            " [  3]\n",
            " [ 29]\n",
            " [  2]\n",
            " [417]\n",
            " [  3]\n",
            " [ 12]\n",
            " [  2]\n",
            " [ 53]\n",
            " [  3]\n",
            " [ 40]\n",
            " [207]\n",
            " [  2]\n",
            " [ 10]\n",
            " [  3]\n",
            " [ 40]\n",
            " [ 19]\n",
            " [ 55]\n",
            " [  3]\n",
            " [422]\n",
            " [  3]\n",
            " [  2]\n",
            " [306]\n",
            " [  5]\n",
            " [369]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 21]\n",
            " [ 60]\n",
            " [  2]\n",
            " [786]\n",
            " [598]\n",
            " [  4]\n",
            " [  2]\n",
            " [480]\n",
            " [  5]\n",
            " [  2]\n",
            " [  2]\n",
            " [  6]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 98]\n",
            " [  9]\n",
            " [  6]\n",
            " [  3]\n",
            " [  9]\n",
            " [114]\n",
            " [  5]\n",
            " [ 65]\n",
            " [  8]\n",
            " [  4]\n",
            " [ 29]\n",
            " [  2]\n",
            " [  2]\n",
            " [  9]\n",
            " [561]\n",
            " [  2]\n",
            " [ 17]\n",
            " [116]\n",
            " [  5]\n",
            " [  2]\n",
            " [ 16]\n",
            " [  2]\n",
            " [  2]\n",
            " [  3]\n",
            " [  4]\n",
            " [  9]\n",
            " [  3]\n",
            " [  2]\n",
            " [363]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 33]\n",
            " [  2]\n",
            " [ 32]\n",
            " [192]\n",
            " [  2]\n",
            " [106]\n",
            " [  2]\n",
            " [  4]\n",
            " [123]\n",
            " [  4]\n",
            " [ 11]\n",
            " [  3]\n",
            " [ 62]\n",
            " [112]\n",
            " [  2]\n",
            " [ 73]\n",
            " [153]\n",
            " [ 83]\n",
            " [272]\n",
            " [ 10]\n",
            " [  9]\n",
            " [389]\n",
            " [  4]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [  7]\n",
            " [235]\n",
            " [ 54]\n",
            " [  3]\n",
            " [321]\n",
            " [  3]\n",
            " [453]\n",
            " [754]\n",
            " [  2]\n",
            " [ 53]\n",
            " [  3]\n",
            " [492]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 53]\n",
            " [  2]\n",
            " [  7]\n",
            " [  4]\n",
            " [121]\n",
            " [142]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  5]\n",
            " [401]\n",
            " [  3]\n",
            " [  2]\n",
            " [ 90]\n",
            " [ 11]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  2]\n",
            " [  3]\n",
            " [665]\n",
            " [ 15]\n",
            " [  8]\n",
            " [230]\n",
            " [658]\n",
            " [398]\n",
            " [149]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 10]\n",
            " [  5]\n",
            " [  4]\n",
            " [224]\n",
            " [  2]\n",
            " [  3]\n",
            " [145]\n",
            " [426]\n",
            " [  2]\n",
            " [610]\n",
            " [486]\n",
            " [  4]\n",
            " [  9]\n",
            " [ 35]\n",
            " [  7]\n",
            " [  4]\n",
            " [ 98]\n",
            " [  2]\n",
            " [722]\n",
            " [597]\n",
            " [  2]\n",
            " [  7]\n",
            " [  2]\n",
            " [  6]\n",
            " [  3]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [136]\n",
            " [  2]\n",
            " [  3]\n",
            " [  3]\n",
            " [  4]\n",
            " [ 85]\n",
            " [  5]\n",
            " [431]\n",
            " [  2]\n",
            " [  8]\n",
            " [  2]\n",
            " [ 29]\n",
            " [  5]\n",
            " [  2]\n",
            " [  2]\n",
            " [401]\n",
            " [  2]\n",
            " [278]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 55]\n",
            " [  2]\n",
            " [  3]\n",
            " [  3]\n",
            " [ 62]\n",
            " [121]\n",
            " [ 19]\n",
            " [  7]\n",
            " [505]\n",
            " [  2]\n",
            " [ 70]\n",
            " [  3]\n",
            " [  2]\n",
            " [436]\n",
            " [ 38]\n",
            " [  6]\n",
            " [151]\n",
            " [  2]\n",
            " [ 21]\n",
            " [  4]\n",
            " [  3]\n",
            " [ 12]\n",
            " [720]\n",
            " [  2]\n",
            " [205]\n",
            " [  9]\n",
            " [  2]\n",
            " [ 12]\n",
            " [ 31]\n",
            " [  6]\n",
            " [  3]\n",
            " [ 71]\n",
            " [121]\n",
            " [692]\n",
            " [  6]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 97]\n",
            " [ 77]\n",
            " [544]\n",
            " [ 16]\n",
            " [  9]\n",
            " [  2]\n",
            " [422]\n",
            " [  3]\n",
            " [  2]\n",
            " [163]\n",
            " [  3]\n",
            " [658]\n",
            " [142]\n",
            " [  2]\n",
            " [  2]\n",
            " [  9]\n",
            " [  2]\n",
            " [  5]\n",
            " [537]\n",
            " [  3]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 58]\n",
            " [ 15]\n",
            " [731]\n",
            " [497]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [621]\n",
            " [  2]\n",
            " [347]\n",
            " [109]\n",
            " [  7]\n",
            " [113]\n",
            " [  4]\n",
            " [152]\n",
            " [ 16]\n",
            " [  2]\n",
            " [  5]\n",
            " [755]\n",
            " [ 10]\n",
            " [  2]\n",
            " [  7]\n",
            " [  4]\n",
            " [547]\n",
            " [  2]\n",
            " [  2]\n",
            " [ 10]\n",
            " [298]\n",
            " [  2]\n",
            " [  2]\n",
            " [  7]\n",
            " [  2]\n",
            " [  2]\n",
            " [  5]\n",
            " [  3]\n",
            " [  3]\n",
            " [  2]\n",
            " [  2]\n",
            " [353]\n",
            " [294]\n",
            " [  2]\n",
            " [  3]\n",
            " [579]\n",
            " [  2]\n",
            " [ 29]\n",
            " [204]\n",
            " [ 67]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]\n",
            " [127]\n",
            " [ 50]\n",
            " [ 35]\n",
            " [  4]\n",
            " [  2]\n",
            " [  6]\n",
            " [ 27]\n",
            " [349]\n",
            " [102]\n",
            " [  3]\n",
            " [  6]\n",
            " [  3]\n",
            " [395]\n",
            " [  3]\n",
            " [172]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 20]\n",
            " [  2]\n",
            " [  3]\n",
            " [ 10]\n",
            " [421]\n",
            " [274]\n",
            " [  2]\n",
            " [  3]\n",
            " [  2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "sonnet_df = pd.read_csv(\"Sonnet_pairs.csv\")\n",
        "def get_head_tail(intersection_words, line_text, intersection_count):\n",
        "  if intersection_count != 2:\n",
        "    return None\n",
        "  intersection_words_list = intersection_words.split('|')\n",
        "  if (line_text.find(intersection_words_list[0]) \n",
        "        < line_text.find(intersection_words_list[1])):\n",
        "    head = intersection_words_list[0]\n",
        "    tail = intersection_words_list[1]\n",
        "  else:\n",
        "    head = intersection_words_list[1]\n",
        "    tail = intersection_words_list[0]\n",
        "  return (head, tail)\n",
        "sonnet_df['Head_tail'] = sonnet_df.apply(lambda x : get_head_tail(x.Intersection_Words, \n",
        "                                                    x.LineText,\n",
        "                                                    x.Intersection_count), axis = 1)\n",
        "sonnet_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3xUtTvCsD7wS",
        "outputId": "d83f57c9-26a1-4d7b-c8c0-ef1863a828da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                           LineText  \\\n",
              "0             1         from fairest creatures we desire increase    \n",
              "1             6  feed st thy light s flame with self substantia...   \n",
              "2             9      thou that art now the world s fresh ornament    \n",
              "3            25    if thou couldst answer  this fair child of mine   \n",
              "4            29      and see thy blood warm when thou feel st i...   \n",
              "..          ...                                                ...   \n",
              "281        2285        which borrow d from this holy fire of love    \n",
              "282        2289    but at my mistress  eye love s brand new fired    \n",
              "283        2290     the boy for trial needs would touch my breast    \n",
              "284        2305        which from love s fire took heat perpetual    \n",
              "285        2309      love s fire heats water  water cools not l...   \n",
              "\n",
              "         Intersection_Words  Intersection_count           Head_tail  \n",
              "0           increase|desire                   2  (desire, increase)  \n",
              "1                feed|light                   2       (feed, light)  \n",
              "2                 art|world                   2        (art, world)  \n",
              "3              answer|child                   2     (answer, child)  \n",
              "4           cold|feel|blood                   3                None  \n",
              "..                      ...                 ...                 ...  \n",
              "281               love|fire                   2        (fire, love)  \n",
              "282                love|eye                   2         (eye, love)  \n",
              "283  touch|breast|trial|boy                   4                None  \n",
              "284               love|fire                   2        (love, fire)  \n",
              "285         love|water|fire                   3                None  \n",
              "\n",
              "[286 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f805dd1-9f02-4faf-9ed7-dafbc2162bde\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>LineText</th>\n",
              "      <th>Intersection_Words</th>\n",
              "      <th>Intersection_count</th>\n",
              "      <th>Head_tail</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>from fairest creatures we desire increase</td>\n",
              "      <td>increase|desire</td>\n",
              "      <td>2</td>\n",
              "      <td>(desire, increase)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>feed st thy light s flame with self substantia...</td>\n",
              "      <td>feed|light</td>\n",
              "      <td>2</td>\n",
              "      <td>(feed, light)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>thou that art now the world s fresh ornament</td>\n",
              "      <td>art|world</td>\n",
              "      <td>2</td>\n",
              "      <td>(art, world)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>if thou couldst answer  this fair child of mine</td>\n",
              "      <td>answer|child</td>\n",
              "      <td>2</td>\n",
              "      <td>(answer, child)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>29</td>\n",
              "      <td>and see thy blood warm when thou feel st i...</td>\n",
              "      <td>cold|feel|blood</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>2285</td>\n",
              "      <td>which borrow d from this holy fire of love</td>\n",
              "      <td>love|fire</td>\n",
              "      <td>2</td>\n",
              "      <td>(fire, love)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>2289</td>\n",
              "      <td>but at my mistress  eye love s brand new fired</td>\n",
              "      <td>love|eye</td>\n",
              "      <td>2</td>\n",
              "      <td>(eye, love)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>2290</td>\n",
              "      <td>the boy for trial needs would touch my breast</td>\n",
              "      <td>touch|breast|trial|boy</td>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>2305</td>\n",
              "      <td>which from love s fire took heat perpetual</td>\n",
              "      <td>love|fire</td>\n",
              "      <td>2</td>\n",
              "      <td>(love, fire)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>2309</td>\n",
              "      <td>love s fire heats water  water cools not l...</td>\n",
              "      <td>love|water|fire</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>286 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f805dd1-9f02-4faf-9ed7-dafbc2162bde')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f805dd1-9f02-4faf-9ed7-dafbc2162bde button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f805dd1-9f02-4faf-9ed7-dafbc2162bde');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from ampligraph.discovery import discover_facts\n",
        "# from ampligraph.discovery import query_topn\n",
        "\n",
        "# # discover_facts(dataset, \n",
        "# #                model, \n",
        "# #                top_n=50, \n",
        "# #                strategy='entity_frequency', \n",
        "# #                max_candidates=100,\n",
        "# #                target_rel= ['clear', 'brilliant'], \n",
        "# #                seed=0)\n",
        "# query_topn(model, top_n=10,\n",
        "#            head='time', relation=None, tail='money',\n",
        "#            ents_to_consider=None, rels_to_consider=None)\n",
        "\n",
        "from ampligraph.discovery import query_topn\n",
        "# for row in sonnet_df.itertuples(index = False):\n",
        "#   if row.Head_tail:\n",
        "#     print(query_topn(model, top_n = 10, head = row.Head_tail[0], \n",
        "#                      relation = None,\n",
        "#                      tail = row.Head_tail[1]))\n",
        "    \n",
        "def get_topn_relations(model, n, head_tail):\n",
        "  if not head_tail:\n",
        "    return None\n",
        "  relations = []\n",
        "  arr = query_topn(model, top_n = n, head = head_tail[0], \n",
        "             relation = None,\n",
        "             tail = head_tail[1])\n",
        "  for triple in arr[0]:\n",
        "    relations.append(triple[1])\n",
        "  return relations\n",
        "\n",
        "sonnet_df['Relations'] = sonnet_df.apply(lambda x : get_topn_relations(model, 10, \n",
        "                                                                  x.Head_tail),\n",
        "                                         axis = 1)\n",
        "# arr = query_topn(model, 10, head = \"time\", relation = None, tail = \"money\")\n",
        "# relations = []\n",
        "# for triple in arr[0]:\n",
        "#   relations.append(triple[1])\n",
        "# print(relations)\n",
        "\n"
      ],
      "metadata": {
        "id": "BE5Pz8w7POEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sonnet_df.to_csv(\"Sonnet_relations.csv\")"
      ],
      "metadata": {
        "id": "uPjfA993dhbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_test)"
      ],
      "metadata": {
        "id": "hEtocYxpHjY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e2a5f1-87f2-4b3a-a135-572e7ef52247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ranks"
      ],
      "metadata": {
        "id": "GSsT7ZaqmeVc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}